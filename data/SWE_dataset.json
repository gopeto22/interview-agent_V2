[
  {
    "id": "se-001",
    "text": "What is the difference between a process and a thread?",
    "type": "conceptual",
    "difficulty": "easy",
    "follow_up_templates": [
      "How do threads within the same process share resources?",
      "What are some common issues that can arise with multithreading?",
      "When would you choose multi-processing over multi-threading?"
    ],
    "ideal_answer_summary": "A process is an independent program in execution with its own memory space, file handles, and system resources, completely isolated from other processes. A thread is a lightweight unit of execution that runs within a process and shares the process's memory space, file handles, and other resources with other threads in the same process. Multiple threads can run concurrently within a single process and communicate through shared memory, while processes communicate through inter-process communication mechanisms. Threads are useful for parallelizing tasks within a single application but require careful synchronization to avoid race conditions, deadlocks, and data corruption when accessing shared resources."
  },
  {
    "id": "se-002",
    "text": "Explain what happens when you type a URL into a web browser and press Enter.",
    "type": "conceptual",
    "difficulty": "hard",
    "follow_up_templates": [
      "What is the role of DNS in this process?",
      "How does the browser establish a secure HTTPS connection?",
      "What happens if the server returns a redirect status code?"
    ],
    "ideal_answer_summary": "The process involves multiple steps: First, the browser parses the URL and checks its cache for DNS records. If not cached, it performs DNS lookup to resolve the domain name to an IP address, potentially querying multiple DNS servers. Next, the browser establishes a TCP connection to the server (including TLS handshake for HTTPS). The browser then sends an HTTP request with headers and method information. The server processes the request, potentially involving load balancers, web servers, application servers, and databases. The server returns an HTTP response with status code, headers, and content. Finally, the browser parses the HTML, requests additional resources like CSS and JavaScript, renders the page, and executes any client-side scripts."
  },
  {
    "id": "se-003",
    "text": "What are ACID properties in the context of databases?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "Why are ACID properties important for financial transactions?",
      "How do NoSQL databases handle ACID properties differently?",
      "What's the difference between isolation levels in databases?"
    ],
    "ideal_answer_summary": "ACID stands for Atomicity, Consistency, Isolation, and Durability - fundamental properties ensuring reliable database transactions. Atomicity guarantees that transactions are all-or-nothing operations; either all changes succeed or none do, preventing partial updates. Consistency ensures that transactions bring the database from one valid state to another, maintaining all constraints and business rules. Isolation prevents concurrent transactions from interfering with each other, making them appear as if they executed sequentially. Durability guarantees that once a transaction commits, its changes persist permanently even in case of system failures. These properties are crucial for maintaining data integrity and reliability in database systems."
  },
  {
    "id": "se-004",
    "text": "What is the CAP theorem in distributed systems?",
    "type": "conceptual",
    "difficulty": "hard",
    "follow_up_templates": [
      "Can you give examples of systems that choose AP versus CP?",
      "How does eventual consistency relate to the CAP theorem?",
      "What trade-offs does the CAP theorem force system designers to make?"
    ],
    "ideal_answer_summary": "The CAP theorem states that in any distributed data store, you can only guarantee at most two out of three properties: Consistency (all nodes see the same data simultaneously), Availability (system remains operational and responds to requests), and Partition tolerance (system continues operating despite network failures). Since network partitions are inevitable in distributed systems, the practical choice is usually between consistency and availability. CP systems prioritize consistency over availability during partitions, while AP systems remain available but may serve stale data. This theorem fundamentally shapes the design decisions in distributed databases and microservices architectures."
  },
  {
    "id": "se-005",
    "text": "What is a deadlock and how can it be prevented?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "What are the four necessary conditions for a deadlock to occur?",
      "How do database systems typically handle deadlock detection?",
      "What's the difference between deadlock prevention and deadlock avoidance?"
    ],
    "ideal_answer_summary": "A deadlock occurs when two or more processes or threads are blocked indefinitely, each waiting for resources held by others, creating a circular dependency. The four necessary conditions are mutual exclusion (resources can't be shared), hold and wait (processes hold resources while requesting others), no preemption (resources can't be forcibly taken), and circular wait (circular chain of processes waiting for resources). Prevention strategies include eliminating one of these conditions through resource ordering, timeouts, or allowing preemption. Detection and recovery approaches periodically check for deadlocks and resolve them by terminating processes or rolling back transactions. Modern systems often use sophisticated algorithms like banker's algorithm for deadlock avoidance."
  },
  {
    "id": "se-006",
    "text": "What is the difference between TCP and UDP in network communication?",
    "type": "conceptual",
    "difficulty": "easy",
    "follow_up_templates": [
      "When would you choose UDP over TCP for an application?",
      "How does TCP ensure reliable data delivery?",
      "What is the three-way handshake in TCP?"
    ],
    "ideal_answer_summary": "TCP (Transmission Control Protocol) is connection-oriented and provides reliable, ordered, error-checked delivery of data through acknowledgments, retransmission, and flow control. It establishes connections via three-way handshake and guarantees that data arrives in order without duplication or corruption. UDP (User Datagram Protocol) is connectionless and provides fast, lightweight transmission without reliability guarantees - it simply sends packets without establishing connections or ensuring delivery. TCP is ideal for applications requiring data integrity like web browsing, email, and file transfers, while UDP suits real-time applications like gaming, video streaming, and DNS queries where speed matters more than perfect delivery."
  },
  {
    "id": "se-007",
    "text": "What is a RESTful API and what are its key principles?",
    "type": "conceptual",
    "difficulty": "easy",
    "follow_up_templates": [
      "How do HTTP methods map to CRUD operations in REST?",
      "What does it mean for an API to be stateless?",
      "How do you handle authentication in a stateless RESTful API?"
    ],
    "ideal_answer_summary": "A RESTful API follows the principles of REST (Representational State Transfer) architecture, using standard HTTP methods to perform operations on resources identified by URLs. Key principles include statelessness (each request contains all necessary information), uniform interface (consistent way to interact with resources), resource-based (everything is a resource with unique URLs), and cacheable responses. HTTP methods map to operations: GET retrieves data, POST creates resources, PUT updates entire resources, PATCH updates partial resources, and DELETE removes resources. REST APIs typically return data in JSON format and use appropriate HTTP status codes to indicate success or failure, making them simple, scalable, and interoperable."
  },
  {
    "id": "se-008",
    "text": "What is the difference between a monolithic architecture and a microservices architecture?",
    "type": "design",
    "difficulty": "medium",
    "follow_up_templates": [
      "What are the main challenges of implementing microservices?",
      "How does deployment differ between monoliths and microservices?",
      "When would you choose a monolithic architecture over microservices?"
    ],
    "ideal_answer_summary": "Monolithic architecture builds the entire application as a single deployable unit where all components are interconnected and interdependent, sharing the same database and runtime. Microservices architecture decomposes the application into small, independent services that communicate via APIs, each with its own database and deployment lifecycle. Monoliths offer simplicity in development, testing, and deployment but can become difficult to scale and maintain as they grow. Microservices provide benefits like independent scaling, technology diversity, fault isolation, and team autonomy, but introduce complexity in service communication, data consistency, distributed system challenges, and operational overhead. The choice depends on team size, system complexity, and scalability requirements."
  },
  {
    "id": "se-009",
    "text": "What are the SOLID principles of object-oriented design?",
    "type": "conceptual",
    "difficulty": "hard",
    "follow_up_templates": [
      "Can you give a practical example of violating the Single Responsibility Principle?",
      "How does dependency injection relate to the Dependency Inversion Principle?",
      "Why is the Open/Closed Principle important for maintainable code?"
    ],
    "ideal_answer_summary": "SOLID represents five object-oriented design principles: Single Responsibility Principle states a class should have only one reason to change; Open/Closed Principle means software entities should be open for extension but closed for modification; Liskov Substitution Principle requires that subclasses should be substitutable for their base classes without altering program correctness; Interface Segregation Principle advocates for many specific interfaces rather than one general-purpose interface; and Dependency Inversion Principle states that high-level modules should depend on abstractions, not concrete implementations. These principles promote maintainable, flexible, and testable code by reducing coupling, increasing cohesion, and enabling easier modifications and extensions."
  },
  {
    "id": "se-010",
    "text": "What are software design patterns and why are they useful?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "Can you explain the Singleton pattern and when to use it?",
      "How does the Observer pattern work in event-driven systems?",
      "What's the difference between Factory and Abstract Factory patterns?"
    ],
    "ideal_answer_summary": "Software design patterns are reusable solutions to common problems in software design and development. They provide templates for solving recurring design challenges and represent best practices evolved over time. Patterns promote code reuse, improve communication among developers through shared vocabulary, and encapsulate design knowledge. Examples include Singleton for ensuring single instance creation, Observer for implementing event notification systems, Factory for object creation abstraction, and Strategy for encapsulating algorithms. Patterns help create more maintainable, flexible, and understandable code by providing proven solutions and establishing consistent approaches to common design problems."
  },
  {
    "id": "se-011",
    "text": "What's the difference between unit testing and integration testing?",
    "type": "conceptual",
    "difficulty": "easy",
    "follow_up_templates": [
      "How do you mock dependencies in unit tests?",
      "What types of bugs are caught by integration tests that unit tests miss?",
      "How does test-driven development relate to unit testing?"
    ],
    "ideal_answer_summary": "Unit testing focuses on testing individual components or functions in isolation, typically mocking external dependencies to ensure tests are fast, reliable, and focused on a single piece of functionality. Integration testing verifies that different components work correctly together, testing the interactions between modules, services, or systems. Unit tests are numerous, run quickly, and help pinpoint exact locations of bugs, while integration tests are fewer, slower, and catch issues related to component interactions, configuration problems, and system-level behavior. Both are essential: unit tests provide rapid feedback during development, while integration tests ensure the system works as a cohesive whole."
  },
  {
    "id": "se-012",
    "text": "How does garbage collection work in programming languages?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "What are the different garbage collection algorithms?",
      "How does reference counting differ from mark-and-sweep?",
      "What are the performance implications of garbage collection?"
    ],
    "ideal_answer_summary": "Garbage collection automatically manages memory by identifying and freeing memory that's no longer reachable or referenced by the program. Common algorithms include mark-and-sweep (marking reachable objects then sweeping unreachable ones), generational collection (separating objects by age since most objects die young), and reference counting (tracking object references). The garbage collector typically runs periodically or when memory pressure occurs, pausing program execution to perform cleanup. While GC prevents memory leaks and dangling pointer errors, it can introduce performance overhead through pause times and memory overhead. Modern collectors use sophisticated techniques like concurrent collection and incremental collection to minimize these impacts."
  },
  {
    "id": "se-013",
    "text": "What is the difference between Continuous Integration and Continuous Deployment?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "What tools are commonly used in CI/CD pipelines?",
      "How does feature flagging relate to continuous deployment?",
      "What are the prerequisites for implementing continuous deployment safely?"
    ],
    "ideal_answer_summary": "Continuous Integration is the practice of frequently merging code changes into a shared repository and automatically building and testing the integrated code to catch integration issues early. Continuous Deployment extends this by automatically deploying all changes that pass the automated test suite to production without human intervention. Continuous Delivery is similar but requires manual approval for production deployment. CI focuses on maintaining code quality and catching issues quickly, while CD emphasizes rapid, reliable delivery to users. Both require robust automated testing, monitoring, and the ability to quickly rollback changes. Together, they enable faster feedback cycles, reduced deployment risk, and more frequent releases."
  },
  {
    "id": "se-014",
    "text": "What's the difference between an abstract class and an interface?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "When would you choose an abstract class over an interface?",
      "How do interfaces support multiple inheritance in languages like Java?",
      "What are default methods in interfaces and why were they added?"
    ],
    "ideal_answer_summary": "An abstract class is a partially implemented class that cannot be instantiated and may contain both abstract methods (without implementation) and concrete methods (with implementation). It can have instance variables, constructors, and access modifiers. An interface defines a contract specifying what methods a class must implement but traditionally contains no implementation (though modern languages allow default methods). Classes can implement multiple interfaces but typically inherit from only one abstract class. Use abstract classes when you want to share code among related classes and provide a common base with partial implementation. Use interfaces when you want to define capabilities that unrelated classes can implement or when you need multiple inheritance-like behavior."
  },
  {
    "id": "se-015",
    "text": "What's the difference between inheritance and composition in object-oriented programming?",
    "type": "conceptual",
    "difficulty": "medium",
    "follow_up_templates": [
      "Why is composition often preferred over inheritance?",
      "How does the 'is-a' versus 'has-a' relationship guide this choice?",
      "What problems can deep inheritance hierarchies cause?"
    ],
    "ideal_answer_summary": "Inheritance establishes an 'is-a' relationship where a subclass inherits properties and methods from a parent class, enabling code reuse and polymorphism but creating tight coupling between classes. Composition establishes a 'has-a' relationship where a class contains instances of other classes as components, achieving functionality through delegation rather than inheritance. Composition provides greater flexibility since you can change behavior by swapping components at runtime, reduces coupling, and avoids issues like the fragile base class problem. While inheritance can be appropriate for true hierarchical relationships, composition is often preferred because it's more flexible, testable, and maintainable, following the principle of favoring composition over inheritance."
  },
  {
    "id": "se-016",
    "text": "Describe your approach to implementing a thread-safe singleton pattern.",
    "type": "coding",
    "difficulty": "medium",
    "follow_up_templates": [
      "What are the different ways to implement thread safety in singleton?",
      "How does double-checked locking work and what are its pitfalls?",
      "Why might you consider avoiding the singleton pattern altogether?"
    ],
    "ideal_answer_summary": "I would implement thread-safe singleton using either lazy initialization with synchronization or eager initialization. For lazy initialization, I'd use double-checked locking pattern where I first check if the instance is null, then synchronize only if needed, and check again inside the synchronized block before creating the instance. This minimizes synchronization overhead. Alternatively, I could use the initialization-on-demand holder pattern which leverages class loading mechanics for thread safety without explicit synchronization. For eager initialization, I'd create the instance as a static final variable, which is thread-safe by default but creates the instance even if never used. I'd also make the constructor private and provide a static getInstance method."
  },
  {
    "id": "se-017",
    "text": "How would you implement a simple caching mechanism?",
    "type": "coding",
    "difficulty": "medium",
    "follow_up_templates": [
      "What eviction policies would you consider for the cache?",
      "How would you handle cache invalidation?",
      "What's the difference between write-through and write-back caching?"
    ],
    "ideal_answer_summary": "I would implement a cache using a hash map for fast key-value lookups combined with a doubly-linked list to track access order for LRU eviction. The cache would have a maximum capacity, and when adding new items that exceed capacity, I'd remove the least recently used item. For each access, I'd move the accessed item to the front of the list. I'd include methods for get, put, and delete operations, ensuring thread safety with appropriate synchronization if needed for concurrent access. I'd also consider adding features like TTL expiration, cache statistics, and configurable eviction policies. The implementation would handle edge cases like null keys or values according to requirements."
  },
  {
    "id": "se-018",
    "text": "Explain your approach to designing a URL shortener service like TinyURL.",
    "type": "design",
    "difficulty": "hard",
    "follow_up_templates": [
      "How would you handle custom aliases and analytics?",
      "What database considerations are important for scale?",
      "How would you implement rate limiting and security measures?"
    ],
    "ideal_answer_summary": "I would design a distributed system with key components including a URL encoding service using base62 encoding for short URLs, a database to store URL mappings with proper indexing, a caching layer for frequently accessed URLs, and load balancers for high availability. The system would use a counter-based approach or hash-based approach for generating unique short codes, with database sharding for horizontal scaling. I'd implement rate limiting to prevent abuse, analytics tracking for click statistics, custom alias support, and URL validation. Security measures would include checking for malicious URLs and implementing expiration times. The architecture would support both SQL and NoSQL databases depending on consistency requirements and would include proper monitoring and logging."
  },
  {
    "id": "se-019",
    "text": "How would you design a chat application backend?",
    "type": "design",
    "difficulty": "hard",
    "follow_up_templates": [
      "How would you implement real-time messaging?",
      "What's your strategy for message persistence and retrieval?",
      "How would you handle user presence and typing indicators?"
    ],
    "ideal_answer_summary": "I would design a scalable chat backend using WebSockets for real-time communication, with multiple components including connection management services, message routing services, user authentication, and message persistence. The architecture would use message queues for reliable message delivery, database sharding for storing chat history, and caching for recent messages and online user status. I'd implement features like message ordering using timestamps or sequence numbers, delivery receipts, typing indicators, user presence status, and support for both one-on-one and group chats. The system would handle connection drops gracefully, implement message encryption for security, and use CDN for media sharing. Load balancing would distribute connections across multiple servers while maintaining session affinity."
  },
  {
    "id": "se-020",
    "text": "Design a distributed logging system for microservices.",
    "type": "design",
    "difficulty": "hard",
    "follow_up_templates": [
      "How would you correlate logs across different services?",
      "What's your approach to log aggregation and analysis?",
      "How would you handle log retention and storage costs?"
    ],
    "ideal_answer_summary": "I would design a centralized logging system with components including log collectors on each service, a message queue for reliable log transport, log aggregation services, and storage optimized for time-series data. The system would use correlation IDs to trace requests across services, structured logging with consistent formats, and log levels for filtering. I'd implement log parsing and enrichment, real-time alerting for critical events, and efficient storage with appropriate retention policies. The architecture would include log rotation, compression, and archival strategies to manage costs. Search and analysis capabilities would be provided through indexing, with dashboards for monitoring and debugging. The system would be fault-tolerant, ensuring logs aren't lost even during service failures, and would support both real-time streaming and batch processing of log data."
  }
]
