# Resume Service Environment Variables

# OpenAI Configuration (for LLM-enhanced extraction)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=o1-mini
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.1

# Application Configuration
DEBUG=true
LOG_LEVEL=INFO
PORT=8003

# File Processing Configuration
MAX_FILE_SIZE_MB=10
SUPPORTED_FORMATS=pdf,docx,doc,txt

# Directory Configuration (relative to service root)
DATA_DIR=data
TEST_FILES_DIR=data/test_files
OUTPUT_DIR=data/output
UPLOADS_DIR=uploads

# Pipeline Configuration
USE_LLM_ENHANCEMENT=false
DEFAULT_CONFIDENCE_THRESHOLD=0.5
EXTRACTION_TIMEOUT_SECONDS=30

# External Services Integration
INTERVIEW_SERVICE_URL=http://localhost:8002
USER_SERVICE_URL=http://localhost:8001

# CORS Configuration
ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:8010"]
ALLOWED_HOSTS=["localhost", "127.0.0.1"]
